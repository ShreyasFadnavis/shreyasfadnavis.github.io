<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>The Missing Connection: When Geometry Meets Distribution-Free Inference &mdash; Shreyas Fadnavis</title>
  <link rel="stylesheet" href="../css/style.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false}]});"></script>
  <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
  <script>mermaid.initialize({startOnLoad: true, theme: 'base', themeVariables: {primaryColor: '#f3f0ec', primaryTextColor: '#1c1917', primaryBorderColor: '#a0522d', lineColor: '#a0522d', secondaryColor: '#faf8f5', tertiaryColor: '#e5e0da'}});</script>
</head>
<body>

<nav>
  <div class="nav-inner">
    <a href="/" class="site-name">Shreyas Fadnavis</a>
    <div class="nav-links">
      <a href="/">About</a>
      <a href="/blog/" class="active">Notes</a>
    </div>
  </div>
</nav>

<main>
  <article class="post">
    <div class="post-header">
      <h1>The Missing Connection: When Geometry Meets Distribution-Free Inference</h1>
      <p class="post-subtitle">Part 10 of a 10-part series on prediction intervals, conformal prediction, and leverage scores.</p>
    </div>

    <div class="series-banner">
      This is part of the series <a href="/blog/">From Predictions to Prediction Intervals</a>.
    </div>

    <div class="post-body">

      <p>This is the final post. For nine installments, we have been building toward a single idea from two different directions. One direction gave us a way to build prediction intervals that work for any model without any distributional assumptions. The other gave us a geometric measure that already knows, for free, where predictions are harder. Each direction is useful on its own, but neither fully solves the problem of adaptive prediction intervals. This post is where the two directions meet.</p>

      <!-- =========================================================== -->
      <!-- LEVEL 1: INTUITIVE                                          -->
      <!-- =========================================================== -->
      <div class="level">
        <div class="level-header" onclick="this.parentElement.querySelector('.level-content').classList.toggle('collapsed'); this.setAttribute('aria-expanded', this.getAttribute('aria-expanded')==='true'?'false':'true');" aria-expanded="true">
          <span class="level-badge intuitive">Intuitive</span>
          <h2>Two Roads, One Destination</h2>
          <span class="level-toggle">&#9662;</span>
        </div>
        <div class="level-content">

          <h3>The Journey So Far</h3>

          <p><strong>Track 1: Conformal Prediction (Posts 1&ndash;3, 8).</strong> We started with a simple observation: point predictions are incomplete. A model that says "420,000" without any indication of confidence is like GPS without the blue circle. We then discovered conformal prediction &mdash; a framework that converts <em>any</em> model's predictions into prediction intervals with a mathematically guaranteed coverage rate. The guarantee is exact, holds in finite samples, and requires no assumptions about the data distribution. But there was a catch: the intervals have the same width everywhere. A prediction in the center of the data gets the same error bar as a prediction at the far edge. Posts 3 and 8 surveyed existing fixes &mdash; CQR, Studentized CP, Localized CP &mdash; and found that each comes with a cost: extra models to train, hyperparameters to tune, or fundamental vulnerabilities like the sign flip.</p>

          <p><strong>Track 2: Leverage Scores (Posts 4&ndash;7, 9).</strong> In parallel, we built up a completely different body of knowledge. The design matrix &mdash; the table of features &mdash; contains a natural map of prediction difficulty. The leverage score of any point tells you, in closed form, how far that point sits from the training data in the directions that matter. High leverage means the model is extrapolating; low leverage means it is interpolating. The prediction error variance is exactly $\sigma^2(1+h)$, where $h$ is the leverage. This formula requires no model training, no hyperparameters, and no residuals. It comes from a single SVD of the design matrix &mdash; an operation that is often already performed when fitting the model. And importantly, it avoids the sign flip that affects residual-based methods: leverage looks at the geometry of the features, not at the residuals.</p>

          <h3>The Convergence</h3>

          <p>These two tracks have been converging from opposite sides of the same problem. Conformal prediction has the <em>engine</em> &mdash; a machine for converting any score into guaranteed prediction intervals. Leverage scores have the <em>steering wheel</em> &mdash; a precise, closed-form measure of where to make intervals wider and where to make them narrower. What if we simply combine them?</p>

          <p>The idea is straightforward: instead of feeding raw residuals into the conformal machine, feed in <em>leverage-weighted</em> residuals. Concretely, you compute the SVD of the design matrix (often already available from the model fit), use it to get each point's leverage score, and then multiply each absolute residual by a weight like $(1+h)^{-1/2}$ before computing the conformal quantile. At prediction time, the interval width is scaled by the inverse of this weight, so high-leverage points get wider intervals and low-leverage points get narrower ones. The conformal guarantee still holds &mdash; it works for any score function. But now the intervals adapt to the geometry of the data: wider where predictions are genuinely harder, narrower where the model is interpolating among dense training data.</p>

          <div class="mermaid">
flowchart LR
    subgraph Track1["Track 1: Conformal Prediction"]
      direction TB
      A1["Data"] --> A2["Model"]
      A2 --> A3["Residuals"]
      A3 --> A4["Conformal Quantile"]
      A4 --> A5["Constant Width\nInterval"]
    end
    subgraph Track2["Track 2: Leverage"]
      direction TB
      B1["Design Matrix"] --> B2["SVD"]
      B2 --> B3["Leverage Scores"]
      B3 --> B4["Weight Function\nw(h) = (1+h)⁻¹ᐟ²"]
    end
    A3 -. "?" .-> M["Leverage-Weighted\nResiduals"]
    B4 --> M
    M --> Q["Conformal Quantile"]
    Q --> I["ADAPTIVE\nInterval"]
    style A5 fill:#fce4ec,stroke:#c62828,color:#1c1917
    style I fill:#e8f5e9,stroke:#2e7d32,color:#1c1917
    style M fill:#e3f2fd,stroke:#1565c0,color:#1c1917
          </div>
          <p class="diagram-caption">Two independent tracks &mdash; conformal prediction and leverage &mdash; converge into a single method that inherits the best of both.</p>

          <p>The coverage guarantee is exact and finite-sample &mdash; inherited directly from the conformal framework. The adaptation mechanism is grounded in classical regression theory &mdash; inherited from leverage. And the computational overhead is modest: a single SVD, plus an $O(p)$ operation per test point to compute each leverage score.</p>

          <h3>What Does This Give Us?</h3>

          <p>Over the course of this series, we have articulated five requirements for a good adaptive prediction interval method. Let us see how the combination fares.</p>

          <div class="mermaid">
flowchart TD
    R1["1. Coverage guarantee\nfor ANY model"]
    R2["2. Adaptive width\nwider where harder"]
    R3["3. No auxiliary models\nno hyperparameters"]
    R4["4. Computationally cheap\none SVD + O&#40;p&#41; per point"]
    R5["5. No sign flip\nno residuals in the weight"]
    R1 --- V1["Conformal framework\nguarantees this"]
    R2 --- V2["Leverage controls\nprediction variance"]
    R3 --- V3["SVD of design matrix\nnothing else needed"]
    R4 --- V4["Already computed\nwhen fitting OLS"]
    R5 --- V5["Weight uses geometry\nnot residuals"]
    style R1 fill:#e8f5e9,stroke:#2e7d32,color:#1c1917
    style R2 fill:#e8f5e9,stroke:#2e7d32,color:#1c1917
    style R3 fill:#e8f5e9,stroke:#2e7d32,color:#1c1917
    style R4 fill:#e8f5e9,stroke:#2e7d32,color:#1c1917
    style R5 fill:#e8f5e9,stroke:#2e7d32,color:#1c1917
          </div>
          <p class="diagram-caption">All five requirements are satisfied by combining conformal prediction with leverage-based weighting.</p>

          <div class="analogy">
            <div class="analogy-label">Analogy</div>
            <p>For 20 years, conformal prediction had the engine but no steering wheel. It could build prediction intervals for any model &mdash; a genuinely useful capability &mdash; but those intervals were the same width everywhere. For 50 years, leverage scores had the steering wheel but no engine. They could tell you where predictions are harder &mdash; but they could not, on their own, produce prediction intervals with finite-sample guarantees. The combination gives you both: a distribution-free engine steered by classical geometric insight.</p>
          </div>

          <h3>Open Questions</h3>

          <p>Of course, several questions remain before this can be considered a complete method. Can it be made mathematically rigorous, with formal optimality results? The variance-stabilization argument is clean in theory, but does it hold up in finite samples when the number of features is not negligible relative to the sample size? What about non-linear models, where the variance formula $\sigma^2(1+h)$ was derived for OLS &mdash; does leverage still capture the right notion of prediction difficulty for random forests or neural networks? And could leverage be combined with a lightweight scale estimator to handle heteroscedasticity that depends on features in ways beyond what geometry captures? For instance, if the noise level varies spatially in a way unrelated to data density, leverage alone cannot account for it, but a small auxiliary model might fill the gap without reintroducing the sign flip.</p>

          <div class="callout">
            <div class="callout-label">Stay Tuned</div>
            <p>The ideas in this series are not just a pedagogical exercise. They point toward a concrete method &mdash; a leverage-based approach to conformal prediction &mdash; with theoretical guarantees and empirical results that we plan to describe in detail. The formal treatment is the subject of ongoing work.</p>
          </div>

        </div>
      </div>

      <!-- =========================================================== -->
      <!-- LEVEL 2: TECHNICAL                                          -->
      <!-- =========================================================== -->
      <div class="level">
        <div class="level-header" onclick="this.parentElement.querySelector('.level-content').classList.toggle('collapsed'); this.setAttribute('aria-expanded', this.getAttribute('aria-expanded')==='true'?'false':'true');" aria-expanded="true">
          <span class="level-badge technical">Technical</span>
          <h2>The Proposal and Its Requirements</h2>
          <span class="level-toggle">&#9662;</span>
        </div>
        <div class="level-content">

          <h3>Leverage-Based Conformal Scores</h3>

          <p>The proposal is to replace the vanilla conformal score $S_i = |Y_i - \hat{f}(X_i)|$ with a leverage-weighted score:</p>

          $$S_i = |Y_i - \hat{f}(X_i)| \cdot w(h(X_i))$$

          <p>where $h(X_i) = X_i^\top (\mathbf{X}^\top \mathbf{X})^{-1} X_i$ is the leverage of the calibration point and $w(h) = (1+h)^{-1/2}$ is the weight function derived from the variance formula in Part 6.</p>

          <p>Given the conformal quantile $\hat{q} = \text{Quantile}_{1-\alpha}\left(\{S_1, \ldots, S_{n_2}, +\infty\}\right)$, the prediction interval at a new point $x$ is:</p>

          $$\hat{C}(x) = \left[\hat{f}(x) - \frac{\hat{q}}{w(h(x))}, \;\; \hat{f}(x) + \frac{\hat{q}}{w(h(x))}\right]$$

          <p>The interval has width $2\hat{q}/w(h(x)) = 2\hat{q}\sqrt{1+h(x)}$. This is wider at high-leverage points and narrower at low-leverage points &mdash; exactly the behavior we want.</p>

          <div class="mermaid">
flowchart TD
    subgraph Training["Step 1: Training Split D₁"]
      T1["Fit model f̂ on D₁"]
      T2["Compute SVD: X = UΣVᵀ"]
      T1 --- T2
    end
    subgraph Calibration["Step 2: Calibration Split D₂"]
      C1["For each (Xᵢ, Yᵢ) in D₂:"]
      C2["Compute h(Xᵢ) = ‖Σ⁻¹VᵀXᵢ‖²"]
      C3["Compute weight w(h) = (1+h)⁻¹ᐟ²"]
      C4["Score Sᵢ = |Yᵢ - f̂(Xᵢ)| · w(h)"]
      C1 --> C2 --> C3 --> C4
    end
    subgraph Quantile["Step 3: Conformal Quantile"]
      Q1["q̂ = Quantile at level\n(1-α)(1 + 1/n₂)\nof {S₁, ..., Sₙ₂}"]
    end
    subgraph Predict["Step 4: Prediction"]
      P1["For new x:"]
      P2["Compute h(x)"]
      P3["Width = 2q̂ / w(h(x))\n= 2q̂ · √(1+h(x))"]
      P1 --> P2 --> P3
    end
    Training --> Calibration --> Quantile --> Predict
          </div>
          <p class="diagram-caption">The leverage-based conformal pipeline, from training through prediction.</p>

          <h3>The Five Requirements</h3>

          <p>Let us check each requirement systematically.</p>

          <p><strong>Requirement 1: Marginal coverage guarantee.</strong> The conformal coverage guarantee (Part 2) depends on exchangeability of the scores, not on their specific form. The weight $w(h(X_i))$ is a deterministic function of $X_i$ given the training set $D_1$. Multiplying exchangeable residuals by a deterministic function of the features preserves exchangeability. Therefore, the marginal coverage guarantee $P(Y_{\text{new}} \in \hat{C}(X_{\text{new}})) \geq 1-\alpha$ holds for <em>any</em> weight function $w$, for <em>any</em> prediction model $\hat{f}$, in finite samples.</p>

          <p><strong>Requirement 2: Improved conditional coverage.</strong> Under a linear model with homoscedastic errors, the prediction error $Y_i - \hat{f}(X_i)$ has variance $\sigma^2(1+h(X_i))$ on the calibration set (Part 6). The weighted score $S_i = |Y_i - \hat{f}(X_i)| \cdot (1+h(X_i))^{-1/2}$ therefore has approximately constant variance $\sigma^2$ across the calibration set. When the scores have constant variance, the conformal quantile estimates the correct conditional quantile at every leverage level &mdash; this is the best possible condition for uniform conditional coverage.</p>

          <p><strong>Requirement 3: No auxiliary models or hyperparameters.</strong> The weight $w(h) = (1+h)^{-1/2}$ is a fixed, known function. The leverage $h(x)$ is computed from the SVD of the design matrix. No model is trained, no hyperparameter is tuned, no cross-validation is performed.</p>

          <p><strong>Requirement 4: Computational efficiency.</strong> One SVD costs $O(n_1 p^2)$, or $O(n_1 p \log p)$ with randomized methods. Each leverage score costs $O(p)$. For most practical datasets, this is negligible compared to the cost of fitting the prediction model.</p>

          <p><strong>Requirement 5: Immunity to the sign flip.</strong> The leverage-based weight uses the design matrix geometry. It does not look at residuals, not training residuals, not calibration residuals. There is no sign to flip. At a high-leverage point with $h = 0.5$, the method correctly assigns width proportional to $\sqrt{1.5}$, while a residual-based method would assign width proportional to $\sqrt{0.5}$ &mdash; underestimating uncertainty by a factor of $\sqrt{3}$.</p>

          <table>
            <thead>
              <tr>
                <th>Requirement</th>
                <th>Satisfied?</th>
                <th>Mechanism</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>1. Marginal coverage</td>
                <td>Yes</td>
                <td>Exchangeability preserved for any $w$</td>
              </tr>
              <tr>
                <td>2. Conditional coverage</td>
                <td>Yes (under linear model)</td>
                <td>Variance stabilization via $w(h) = (1+h)^{-1/2}$</td>
              </tr>
              <tr>
                <td>3. No auxiliary models</td>
                <td>Yes</td>
                <td>$w$ is a fixed function of SVD</td>
              </tr>
              <tr>
                <td>4. Computationally cheap</td>
                <td>Yes</td>
                <td>One SVD + $O(p)$ per point</td>
              </tr>
              <tr>
                <td>5. No sign flip</td>
                <td>Yes</td>
                <td>No residuals used in weight</td>
              </tr>
            </tbody>
          </table>

          <div class="mermaid">
flowchart LR
    subgraph Requirements
      direction TB
      R1["Marginal coverage"]
      R2["Conditional coverage"]
      R3["No auxiliary models"]
      R4["Computational efficiency"]
      R5["Sign-flip immunity"]
    end
    subgraph Sources["Source of Guarantee"]
      direction TB
      S1["Exchangeability\n&#40;conformal framework&#41;"]
      S2["Variance stabilization\n&#40;leverage theory&#41;"]
      S3["Fixed function of SVD\n&#40;closed form&#41;"]
      S4["One SVD + O&#40;p&#41;\n&#40;linear algebra&#41;"]
      S5["Design matrix geometry\n&#40;no residuals&#41;"]
    end
    R1 --> S1
    R2 --> S2
    R3 --> S3
    R4 --> S4
    R5 --> S5
          </div>
          <p class="diagram-caption">Each of the five requirements is satisfied by a specific property of the leverage-weighted approach.</p>

          <div class="callout">
            <div class="callout-label">The Key Insight</div>
            <p>Coverage holds for <em>any</em> weight function $w$ &mdash; this is the strength of the conformal framework. But <em>efficiency</em> depends on choosing $w$ well. The leverage-based weight is not arbitrary; it is the variance-stabilizing weight from the theory of heteroscedastic regression. Under a homoscedastic linear model, it is the unique weight that makes the scores approximately i.i.d., which is the optimal condition for the conformal quantile to be informative at every leverage level.</p>
          </div>

        </div>
      </div>

      <!-- =========================================================== -->
      <!-- LEVEL 3: ADVANCED                                           -->
      <!-- =========================================================== -->
      <div class="level">
        <div class="level-header" onclick="this.parentElement.querySelector('.level-content').classList.toggle('collapsed'); this.setAttribute('aria-expanded', this.getAttribute('aria-expanded')==='true'?'false':'true');" aria-expanded="true">
          <span class="level-badge advanced">Advanced</span>
          <h2>Formal Arguments and Open Questions</h2>
          <span class="level-toggle">&#9662;</span>
        </div>
        <div class="level-content">

          <h3>Formal Coverage Argument</h3>

          <p>We make the coverage argument precise. Consider the split conformal setup: a training set $D_1 = \{(X_i, Y_i)\}_{i=1}^{n_1}$ used to fit the model and compute leverage scores, and a calibration set $D_2 = \{(X_j, Y_j)\}_{j=1}^{n_2}$ used to compute conformal scores, with the test point $(X_{\text{new}}, Y_{\text{new}})$. The training set is held fixed throughout the argument; all randomness comes from the calibration and test data. We assume that the calibration and test points are exchangeable (the standard conformal assumption).</p>

          <p>Given $D_1$, we fit a model $\hat{f}$ and compute the SVD of the design matrix $\mathbf{X}_1 = \mathbf{U\Sigma V}^\top$. The weight function $w(h(x)) = (1 + \|\Sigma^{-1}V^\top x\|^2)^{-1/2}$ is now a <em>deterministic</em> function of $x$, conditional on $D_1$. Define the weighted scores:</p>

          $$S_j = |Y_j - \hat{f}(X_j)| \cdot w(h(X_j)), \quad j = 1, \ldots, n_2$$

          $$S_{\text{new}} = |Y_{\text{new}} - \hat{f}(X_{\text{new}})| \cdot w(h(X_{\text{new}}))$$

          <p>Conditional on $D_1$, the model $\hat{f}$ and the weight function $w \circ h$ are fixed. The residual $R_j = Y_j - \hat{f}(X_j)$ is a deterministic function of $(X_j, Y_j)$ and $D_1$. Multiplying $|R_j|$ by the deterministic function $w(h(X_j))$ preserves the symmetry structure. Since $(X_1, Y_1), \ldots, (X_{n_2}, Y_{n_2}), (X_{\text{new}}, Y_{\text{new}})$ are exchangeable conditional on $D_1$, the scores $S_1, \ldots, S_{n_2}, S_{\text{new}}$ are exchangeable conditional on $D_1$.</p>

          <p>By the rank uniformity argument (Part 2), the rank of $S_{\text{new}}$ among $\{S_1, \ldots, S_{n_2}, S_{\text{new}}\}$ is uniformly distributed on $\{1, \ldots, n_2 + 1\}$. Therefore:</p>

          $$P\left(S_{\text{new}} \leq \text{Quantile}_{(1-\alpha)(1+1/n_2)}\{S_1, \ldots, S_{n_2}\}\right) \geq 1-\alpha$$

          <p>Substituting $S_{\text{new}} = |Y_{\text{new}} - \hat{f}(X_{\text{new}})| \cdot w(h(X_{\text{new}}))$ and rearranging:</p>

          $$P\left(|Y_{\text{new}} - \hat{f}(X_{\text{new}})| \leq \frac{\hat{q}}{w(h(X_{\text{new}}))}\right) \geq 1-\alpha$$

          <p>This gives the prediction interval $\hat{f}(X_{\text{new}}) \pm \hat{q}/w(h(X_{\text{new}}))$ with marginal coverage at least $1-\alpha$. The argument is exact and finite-sample. It holds for any model $\hat{f}$, any weight function $w$, and any joint distribution of the data.</p>

          <div class="mermaid">
flowchart TD
    A["Exchangeability of\ncalibration + test points\n(conditional on D₁)"]
    B["w(h(x)) is deterministic\ngiven D₁"]
    C["Weighted scores\nSⱼ = |Rⱼ| · w(hⱼ)\nare exchangeable"]
    D["Rank of Sₙₑw\nis uniform on\n{1, ..., n₂+1}"]
    E["Marginal coverage\nP(Yₙₑw ∈ C(x))\n≥ 1 - α"]
    A --> C
    B --> C
    C --> D
    D --> E
    style E fill:#e8f5e9,stroke:#2e7d32,color:#1c1917
          </div>
          <p class="diagram-caption">The logical structure of the coverage argument. The key step is that the weight is deterministic conditional on $D_1$, preserving exchangeability.</p>

          <h3>The Efficiency Question</h3>

          <p>The coverage guarantee holds for <em>any</em> weight function &mdash; including the identity (vanilla CP), the constant function (also vanilla CP), and even adversarially chosen weights. So the guarantee alone cannot distinguish good weights from bad ones. The question is <em>efficiency</em>: does the leverage-based weight produce intervals that are informative about the conditional quantile?</p>

          <p>Consider the scale family model: $Y_i - \hat{f}(X_i) = \sigma \sqrt{g(h_i)} \cdot \eta_i$, where $\eta_i$ are i.i.d. with $\mathbb{E}[\eta_i] = 0$ and $\text{Var}(\eta_i) = 1$. If $g(h) = 1 + h$ (the homoscedastic linear model case), then with weight $w(h) = (1+h)^{-1/2}$:</p>

          $$S_i = |Y_i - \hat{f}(X_i)| \cdot (1+h_i)^{-1/2} = \sigma |\eta_i|$$

          <p>The weighted scores are <em>i.i.d.</em>, not merely variance-stabilized. They are identically distributed regardless of leverage. This is the strongest possible condition for the conformal quantile to be a good estimator of the conditional quantile everywhere: if the scores are i.i.d., the $(1-\alpha)$-quantile of the scores is the $(1-\alpha)$-quantile of $\sigma|\eta|$, which is the correct conditional quantile at every leverage level (after inverting the weight).</p>

          <p>No other weight achieves this under the homoscedastic linear model. Any other $w$ leaves residual dependence on $h$ in the score distribution, meaning the conformal quantile is an average over an inhomogeneous set of scores &mdash; too conservative in some regions and too liberal in others. In practice, this shows up as intervals that over-cover in the bulk of the data (low leverage) and under-cover in the tails (high leverage), precisely the behavior we see with vanilla conformal prediction.</p>

          <h3>Open Questions Formalized</h3>

          <p>The above argument is clean in the idealized setting. Several questions arise when the assumptions are relaxed.</p>

          <p><strong>Finite-sample behavior when $p/n$ is not small.</strong> The variance formula $\sigma^2(1+h)$ holds exactly for OLS under homoscedastic errors, but the scale family approximation $S_i \approx \sigma|\eta_i|$ requires the weighted scores to be approximately identically distributed. When $p/n$ is moderate (say 0.1 to 0.3), the estimation error term $\sigma^2 h(x)$ is non-negligible, and the higher-order behavior of leverage scores (their distribution, concentration, and interaction with the error distribution) affects whether variance stabilization actually works. What are the finite-sample bounds on conditional coverage as a function of $p/n$? Even approximate answers would help practitioners decide when leverage weighting is likely to help and when it is not worth the effort.</p>

          <p><strong>Model misspecification.</strong> Under model misspecification, the prediction residual $Y - \hat{f}(X)$ includes both the irreducible error and the approximation error from misspecification. The approximation error may depend on features in ways not captured by leverage. Marginal coverage is unaffected (the conformal guarantee holds regardless). But does leverage-based weighting still improve conditional coverage under misspecification, or does the approximation error dominate? One could imagine that leverage weighting helps when the misspecification is mild (e.g., omitting a small interaction term) but becomes irrelevant when the model is badly wrong. Characterizing this boundary would be useful.</p>

          <p><strong>Approximate leverage via randomized SVD.</strong> Randomized SVD computes leverage scores approximately in $O(n_1 p \log p)$ time. If $\tilde{h}(x)$ is an approximation to $h(x)$ with $|\tilde{h}(x) - h(x)| \leq \delta$, the marginal coverage guarantee still holds exactly (the approximation error is absorbed into the score function, which can be arbitrary). But how does the approximation error $\delta$ affect interval width and conditional coverage? Specifically, if $\tilde{w}(x) = (1 + \tilde{h}(x))^{-1/2}$, the width ratio at any point is:</p>

          $$\frac{\tilde{w}(x)}{w(x)} = \sqrt{\frac{1+h(x)}{1+\tilde{h}(x)}} = 1 + O(\delta)$$

          <p>So the width approximation error is at most $O(\delta)$ multiplicatively, which is typically small for well-implemented randomized SVD.</p>

          <p><strong>Non-linear models.</strong> The formula $\sigma^2(1+h)$ is derived for OLS. For non-linear models (random forests, neural networks, boosted trees), leverage is computed from the raw design matrix and is no longer tied to the model's prediction mechanism. Marginal coverage still holds (the conformal guarantee is model-free). But does leverage-based adaptation help? The hypothesis is that it does, because leverage captures the <em>data geometry</em> &mdash; which regions of feature space are data-sparse &mdash; and data sparsity affects prediction difficulty regardless of the model class. Formalizing this requires a theory of effective leverage for non-linear models. One possible direction is to compute leverage from a linearization of the model (e.g., the Jacobian of a neural network), which would recover the classical theory locally while remaining applicable to expressive model classes.</p>

          <p><strong>Combination with learned scale estimation.</strong> When the noise variance depends on features in ways not captured by leverage alone &mdash; for instance, $\text{Var}(\varepsilon \mid X) = \sigma^2(X)$ where $\sigma^2(X)$ is an arbitrary function of features &mdash; leverage weighting handles only the geometric component. A natural extension is:</p>

          $$S_i = \frac{|Y_i - \hat{f}(X_i)|}{\hat{\sigma}(X_i) \cdot \sqrt{1 + h(X_i)}}$$

          <p>where $\hat{\sigma}(X_i)$ is a lightweight estimate of the feature-dependent noise scale. The leverage factor $\sqrt{1+h}$ handles the geometric heteroscedasticity, while $\hat{\sigma}$ handles the remaining feature-dependent heteroscedasticity. A key question: does the leverage component mitigate the sign flip problem for the scale estimator? The sign flip arises because training residual variance is $\sigma^2(1-h)$ while prediction variance is $\sigma^2(1+h)$. If the scale estimator learns $\hat{\sigma}(x) \approx \sigma(x)\sqrt{1-h(x)}$ (wrong sign) but the leverage factor corrects by $\sqrt{1+h(x)}$, the composite $\hat{\sigma}(x) \cdot \sqrt{1+h(x)} \approx \sigma(x)\sqrt{1-h(x)^2}$ may be a better approximation than $\hat{\sigma}(x)$ alone.</p>

          <p>These questions suggest a natural research program: formalize the method, establish finite-sample bounds, characterize the regimes where leverage weighting helps most, and validate the theory with experiments across a range of settings.</p>

          <div class="callout">
            <div class="callout-label">The Program Ahead</div>
            <p>The ideas in this series point toward a concrete algorithm &mdash; a leverage-based approach to conformal prediction &mdash; with provable properties and practical advantages. The formal treatment, including finite-sample theory, misspecification analysis, and experiments on both synthetic and real data, is the subject of upcoming work. The connection between leverage geometry and distribution-free inference is, we believe, a natural one that deserves careful investigation.</p>
          </div>

        </div>
      </div>

    </div>

    <div class="further-reading">
      <h3>Further Reading</h3>
      <ul>
        <li>Vovk, V., Gammerman, A., &amp; Shafer, G. (2005). <em>Algorithmic Learning in a Random World.</em> Springer.</li>
        <li>Hoaglin, D. C. &amp; Welsch, R. E. (1978). The hat matrix in regression and ANOVA. <em>The American Statistician</em>.</li>
        <li>Lei, J., G'Sell, M., Rinaldo, A., Tibshirani, R. J., &amp; Wasserman, L. (2018). Distribution-free predictive inference for regression. <em>JASA</em>.</li>
      </ul>
    </div>

    <div class="post-nav">
      <a href="post09.html" class="prev">Leverage as a Free Lunch</a>
    </div>

  </article>
</main>

<footer>
  <span>Shreyas Fadnavis</span>
  <span><a href="/blog/">Notes</a></span>
</footer>

<script src="../js/lightbox.js"></script>
</body>
</html>
