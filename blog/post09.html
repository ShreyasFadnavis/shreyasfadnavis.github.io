<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Leverage as a Free Lunch: Four Properties You Already Paid For &mdash; Shreyas Fadnavis</title>
  <link rel="stylesheet" href="../css/style.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
    onload="renderMathInElement(document.body, {delimiters: [{left: '$$', right: '$$', display: true}, {left: '$', right: '$', display: false}]});"></script>
  <script src="https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.min.js"></script>
  <script>mermaid.initialize({startOnLoad: true, theme: 'base', themeVariables: {primaryColor: '#f3f0ec', primaryTextColor: '#1c1917', primaryBorderColor: '#a0522d', lineColor: '#a0522d', secondaryColor: '#faf8f5', tertiaryColor: '#e5e0da'}});</script>
</head>
<body>

<nav>
  <div class="nav-inner">
    <a href="/" class="site-name">Shreyas Fadnavis</a>
    <div class="nav-links">
      <a href="/">About</a>
      <a href="/blog/" class="active">Notes</a>
    </div>
  </div>
</nav>

<main>
  <article class="post">
    <div class="post-header">
      <h1>Leverage as a Free Lunch: Four Properties You Already Paid For</h1>
      <p class="post-subtitle">Part 9 of a 10-part series on prediction intervals, conformal prediction, and leverage scores.</p>
    </div>

    <div class="series-banner">
      This is part of the series <a href="/blog/">From Predictions to Prediction Intervals</a>.
    </div>

    <div class="post-body">

      <p>Over the last eight posts, we have built two separate stories. One is about conformal prediction: distribution-free prediction intervals that come with a coverage guarantee but have constant width. The other is about leverage scores: a geometric quantity, extracted from the design matrix, that controls exactly how prediction variance varies across feature space.</p>

      <p>This post makes the case that leverage scores are a <em>free lunch</em> for adaptive uncertainty estimation. In economics, "there is no free lunch" means every benefit has a hidden cost. Leverage scores are the exception: they are already computed as a byproduct of fitting the model. No extra training, no extra data, no extra parameters. The information is simply there, waiting to be used.</p>

      <p>We develop this argument at three progressive levels. The first builds intuition through analogies and comparisons. The second makes the claims precise with formulas. The third provides formal justifications and extensions.</p>

      <!-- =========================================================== -->
      <!-- LEVEL 1: INTUITIVE                                          -->
      <!-- =========================================================== -->
      <div class="level">
        <div class="level-header" onclick="this.parentElement.querySelector('.level-content').classList.toggle('collapsed'); this.setAttribute('aria-expanded', this.getAttribute('aria-expanded')==='true'?'false':'true');" aria-expanded="true">
          <span class="level-badge intuitive">Intuitive</span>
          <h2>The Free Lunch</h2>
          <span class="level-toggle">&#9662;</span>
        </div>
        <div class="level-content">

          <h3>What Makes It Free?</h3>

          <p>When you fit a linear regression, you compute a matrix decomposition of your design matrix (the table of features). This decomposition &mdash; the SVD &mdash; is the engine that produces the model's coefficients. But hidden inside that same decomposition, at no extra cost, is a number for each data point called its <em>leverage score</em>. This number tells you how unusual that point's features are relative to the rest of the data.</p>

          <p>The leverage score is like a receipt stapled to the back of your model. You already paid for it when you fit the model. You just need to flip the receipt over and read it.</p>

          <p>In concrete terms, this means the following. Suppose you have already fit a linear regression on a dataset with 1,000 rows and 30 features. To get adaptive prediction intervals using leverage, you need to store one $30 \times 30$ matrix (from the SVD you already computed) and perform one small matrix-vector product per test point. That is it &mdash; a few microseconds of additional work per prediction. No retraining, no new datasets, no validation loops.</p>

          <p>Every other method for making prediction intervals adaptive requires <em>additional</em> work beyond fitting the base model: training extra models, selecting hyperparameters, or running expensive per-point computations. Leverage asks for nothing extra. This distinction matters in practice: in production systems where prediction latency is constrained, or in scientific settings where computational budgets are tight, the difference between "zero additional cost" and "train two more models" is often the difference between adopting adaptive intervals or not.</p>

          <h3>The Four Properties</h3>

          <p>Leverage scores have four properties that, taken together, distinguish them from every other adaptation mechanism:</p>

          <ol>
            <li><strong>Closed-form.</strong> There is a fixed formula for the weight function. You plug in the leverage score, and you get the answer. Nothing to tune, nothing to search over, nothing to cross-validate. The formula is: divide by the square root of one plus the leverage.</li>
            <li><strong>Model-free.</strong> Leverage is computed from the <em>data</em> (the feature matrix), not from any particular model. It measures how unusual a point's features are, regardless of whether you are using linear regression, a random forest, or a neural network. The geometric content &mdash; "this point is in a sparse region of feature space" &mdash; does not depend on your prediction method.</li>
            <li><strong>Computationally negligible.</strong> One matrix decomposition, which you probably already computed when fitting the model. After that, each new point's leverage costs a handful of multiplications &mdash; far less than making a prediction with a random forest, let alone training a new model.</li>
            <li><strong>Immune to the sign flip.</strong> In Part 6, we saw that training residuals are <em>compressed</em> at high-leverage points while prediction errors are <em>amplified</em>. Any method that estimates uncertainty from training residuals gets the direction backwards at high-leverage points. Leverage does not look at residuals at all. It is computed from the feature matrix. There is no sign to flip.</li>
          </ol>

          <div class="mermaid">
flowchart LR
    subgraph Methods["Method Comparison"]
        direction TB
        L["Leverage-Based"]
        C["CQR"]
        S["Studentized CP"]
        LC["Localized CP"]
    end

    subgraph Props["Properties"]
        direction TB
        P1["Closed-form formula"]
        P2["Model-free"]
        P3["Near-zero extra cost"]
        P4["Immune to sign flip"]
    end

    L --- P1
    L --- P2
    L --- P3
    L --- P4

    C -. "Needs 2 extra models" .-> P1
    S -. "Needs 1 extra model" .-> P1
    LC -. "Needs kernel + bandwidth" .-> P1

    style L fill:#e8f5e9,stroke:#2e7d32,color:#1c1917
    style C fill:#fce4ec,stroke:#c62828,color:#1c1917
    style S fill:#fce4ec,stroke:#c62828,color:#1c1917
    style LC fill:#fce4ec,stroke:#c62828,color:#1c1917
    style P1 fill:#e3f2fd,stroke:#1565c0,color:#1c1917
    style P2 fill:#e3f2fd,stroke:#1565c0,color:#1c1917
    style P3 fill:#e3f2fd,stroke:#1565c0,color:#1c1917
    style P4 fill:#e3f2fd,stroke:#1565c0,color:#1c1917
          </div>
          <p class="diagram-caption">Among these methods, only leverage-based weighting has all four properties. Each alternative lacks at least two.</p>

          <h3>How It Works, Without Any Math</h3>

          <p>Here is the complete pipeline, from raw data to adaptive prediction intervals, using leverage:</p>

          <div class="mermaid">
flowchart LR
    A["Design Matrix X"] --> B["SVD\n(already computed!)"]
    B --> C["Leverage Scores\nh(x) per point"]
    C --> D["Weight Function\nw(h) = 1 / √(1+h)"]
    D --> E["Adaptive Intervals\nWider where h is large\nNarrower where h is small"]

    style A fill:#f3f0ec,stroke:#a0522d,color:#1c1917
    style B fill:#e8f5e9,stroke:#2e7d32,color:#1c1917
    style C fill:#e3f2fd,stroke:#1565c0,color:#1c1917
    style D fill:#e3f2fd,stroke:#1565c0,color:#1c1917
    style E fill:#e8f5e9,stroke:#2e7d32,color:#1c1917
          </div>
          <p class="diagram-caption">The leverage pipeline: the SVD is already computed, so the extra cost is nearly zero.</p>

          <p>Compare this to what the alternatives require:</p>

          <ul>
            <li><strong>CQR</strong> needs two extra quantile regression models. Each requires choosing a model class, setting hyperparameters, and spending significant compute on training. In practice, this at least doubles the engineering effort and computational cost of the uncertainty estimation step.</li>
            <li><strong>Studentized CP</strong> needs one extra scale-estimation model, and it inherits the sign flip problem: it learns the wrong variance at high-leverage points. The method is most inaccurate precisely where accurate uncertainty estimates matter most &mdash; at unusual feature combinations far from the training distribution.</li>
            <li><strong>Localized CP</strong> is expensive at prediction time: it must compare each test point to every calibration point, with a kernel function and bandwidth that need to be chosen. For large test sets, this cost grows rapidly and can become a bottleneck.</li>
          </ul>

          <div class="analogy">
            <div class="analogy-label">Analogy</div>
            <p>Other methods for adaptive prediction intervals are like purchasing a separate navigation system for a car that already has one built in. Leverage is the built-in system: it was installed when the model was assembled, it works reliably, and it costs nothing to turn on.</p>
          </div>

          <h3>When Does Leverage Actually Help?</h3>

          <p>Leverage-based adaptation helps when different points have meaningfully <em>different</em> leverage scores. If every point in the data has roughly the same leverage, the weights are roughly constant, and there is nothing to adapt. The method still works &mdash; it just reduces to the vanilla constant-width intervals. This is a graceful degradation, not a failure: you lose nothing by trying.</p>

          <p>There is a simple diagnostic you can compute before committing to any method. Compute the <strong>leverage dispersion ratio</strong>: the standard deviation of the leverage scores divided by their mean. If this ratio is greater than 1, there is substantial variation, and leverage-based adaptation will noticeably improve interval quality. If the ratio is between 0.5 and 1, there is moderate variation, and the improvement will be real but not dramatic. If the ratio is below 0.5, leverage variation is mild, and the intervals will be similar to constant-width ones. Importantly, this diagnostic itself is free &mdash; it requires only the leverage scores you have already computed.</p>

          <div class="mermaid">
flowchart TD
    A["Compute leverage scores\non calibration set"] --> B["Compute dispersion ratio\nη = std(h) / mean(h)"]
    B --> C{"η > 1?"}
    C -->|Yes| D["Large leverage variation\nLeverage weighting\nhelps significantly"]
    C -->|No| E{"η > 0.5?"}
    E -->|Yes| F["Moderate variation\nLeverage weighting\nhelps somewhat"]
    E -->|No| G["Mild variation\nLeverage weighting\nsimilar to vanilla CP"]

    style D fill:#e8f5e9,stroke:#2e7d32,color:#1c1917
    style F fill:#e3f2fd,stroke:#1565c0,color:#1c1917
    style G fill:#fce4ec,stroke:#c62828,color:#1c1917
          </div>
          <p class="diagram-caption">The leverage dispersion diagnostic: a quick check for whether leverage-based adaptation will help.</p>

          <p>When does leverage variation tend to be large? Two situations stand out. First, when the number of features $p$ is a non-negligible fraction of the number of training points (say, $p/n > 0.05$). In this regime, individual data points have enough influence on the fit that their geometric position matters. Second, when the features have a "spiked" structure &mdash; a few dominant directions with most features being near-redundant. This is common in datasets with correlated features, where a handful of principal components explain most of the variance and a point that is unusual along those components will have high leverage. In modern datasets with many features and moderate sample sizes, one or both conditions are often present.</p>

          <div class="callout">
            <div class="callout-label">Key Insight</div>
            <p>Leverage scores provide a zero-cost description of where prediction uncertainty is amplified by feature-space geometry. They are computed as a byproduct of model fitting, require no tuning, work with any prediction method, and avoid the sign-flip problem that affects residual-based approaches.</p>
          </div>

        </div>
      </div>

      <!-- =========================================================== -->
      <!-- LEVEL 2: TECHNICAL                                          -->
      <!-- =========================================================== -->
      <div class="level">
        <div class="level-header" onclick="this.parentElement.querySelector('.level-content').classList.toggle('collapsed'); this.setAttribute('aria-expanded', this.getAttribute('aria-expanded')==='true'?'false':'true');" aria-expanded="true">
          <span class="level-badge technical">Technical</span>
          <h2>The Four Properties, Made Precise</h2>
          <span class="level-toggle">&#9662;</span>
        </div>
        <div class="level-content">

          <h3>What the SVD Already Gives Us</h3>

          <p>After fitting OLS on training data $\mathcal{D}_1$, we compute the thin SVD: $\mathbf{X} = \mathbf{U\Sigma V}^\top$. From this single decomposition, we have:</p>

          <ol>
            <li>The model: $\hat{f}(x) = x^\top \hat{\beta}$, where $\hat{\beta} = \mathbf{V\Sigma}^{-1}\mathbf{U}^\top \mathbf{Y}$.</li>
            <li>Leverage scores: $h(x) = \|\mathbf{\Sigma}^{-1}\mathbf{V}^\top x\|^2$ for any point $x$, computable in $O(p)$ time.</li>
            <li>The prediction variance formula: $\text{Var}(Y_{\text{new}} - \hat{Y}(x)) = \sigma^2(1 + h(x))$.</li>
          </ol>

          <p>Everything that follows is a consequence of these three facts. Nothing additional needs to be estimated or learned.</p>

          <h3>Property 1: Closed-Form Weight</h3>

          <p>The variance formula $\sigma^2(1+h(x))$ means that prediction errors are <em>not</em> identically distributed. Larger leverage means larger variance. To make them comparable, we divide by the scale factor:</p>

          $$w(h) = (1 + h)^{-1/2}$$

          <p>This is the leverage-based weight function. It is a known formula of a known quantity. There is no estimation step, no tuning parameter, no model selection. The formula is derived from the exact variance decomposition (Part 6), not from an approximation.</p>

          <p>Compare: CQR requires choosing two quantile regression models, each with its own architecture and hyperparameters. Studentized CP requires choosing a scale estimation model. Both involve cross-validation or other tuning procedures. The leverage weight involves none of this.</p>

          <h3>Property 2: Depends Only on the Design Matrix</h3>

          <p>The hat matrix $\mathbf{H} = \mathbf{X}(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top$ is a property of $\mathbf{X}$ alone. It does not depend on the response $\mathbf{Y}$, the model $\hat{f}$, or the noise distribution. The leverage score $h(x) = x^\top(\mathbf{X}^\top\mathbf{X})^{-1}x$ is similarly model-free.</p>

          <p>This has a powerful consequence: you can use leverage-based weights even when the prediction model is not OLS. If you fit a random forest, a neural network, or any other model, you can still compute leverage scores from the raw feature matrix $\mathbf{X}$ and use them to weight the conformal scores. The coverage guarantee of weighted conformal prediction holds for <em>any</em> weight function and <em>any</em> model (Part 2). The leverage weights will correctly identify where the feature-space geometry makes prediction harder, regardless of the prediction method.</p>

          <h3>Property 3: Computational Cost</h3>

          <p>The total cost of leverage-based adaptation breaks down as follows:</p>

          <ul>
            <li><strong>SVD of $\mathbf{X}$:</strong> $O(n_1 p^2)$. This is typically already computed as part of fitting OLS.</li>
            <li><strong>Leverage for $n_2$ calibration points:</strong> $O(n_2 \cdot p)$. One matrix-vector product per point.</li>
            <li><strong>Leverage for $n_{\text{test}}$ test points:</strong> $O(n_{\text{test}} \cdot p)$. Same operation.</li>
          </ul>

          <p>Total additional cost beyond model fitting: $O((n_2 + n_{\text{test}}) \cdot p)$.</p>

          <div class="mermaid">
flowchart LR
    subgraph Leverage["Leverage-Based"]
        direction TB
        L1["SVD: O(n p²)\n(already done)"]
        L2["Scores: O(nᶜᵃˡ · p)"]
        L3["Total extra: ~10⁶ ops"]
    end

    subgraph CQR_cost["CQR"]
        direction TB
        C1["Train 2 quantile models"]
        C2["Each: O(n · trees · p · depth)"]
        C3["Total extra: ~10⁸ ops"]
    end

    subgraph Student["Studentized CP"]
        direction TB
        S1["Train 1 scale model"]
        S2["O(n · trees · p · depth)"]
        S3["Total extra: ~10⁷ ops"]
    end

    subgraph Local["Localized CP"]
        direction TB
        Lo1["Kernel per test point"]
        Lo2["O(nᶜᵃˡ) per test point"]
        Lo3["Total: ~5 · 10⁷ ops"]
    end

    style L3 fill:#e8f5e9,stroke:#2e7d32,color:#1c1917
    style C3 fill:#fce4ec,stroke:#c62828,color:#1c1917
    style S3 fill:#fce4ec,stroke:#c62828,color:#1c1917
    style Lo3 fill:#fce4ec,stroke:#c62828,color:#1c1917
          </div>
          <p class="diagram-caption">Computational cost comparison for $n_1 = 1000$, $n_2 = 500$, $p = 30$, $n_{\text{test}} = 1000$. Leverage is one to two orders of magnitude cheaper.</p>

          <h3>Property 4: No Residuals, No Sign Flip</h3>

          <p>The sign flip (Part 6) is the observation that training residuals have variance $\sigma^2(1 - h_i)$ while prediction errors have variance $\sigma^2(1 + h(x))$. Any method that estimates the scale function from training residuals &mdash; including Studentized CP &mdash; learns a function that <em>decreases</em> at high leverage, when the truth <em>increases</em>.</p>

          <p>Leverage scores bypass this entirely. They are computed from $\mathbf{X}$, not from residuals. The formula $\sigma^2(1+h)$ describes prediction-time variance <em>directly</em>. At a high-leverage point with $h = 0.5$:</p>

          <ul>
            <li>Leverage-based method: width $\propto \sqrt{1 + 0.5} = \sqrt{1.5} \approx 1.22$.</li>
            <li>Residual-based method: learns width $\propto \sqrt{1 - 0.5} = \sqrt{0.5} \approx 0.71$.</li>
          </ul>

          <p>The residual-based method underestimates the uncertainty by a factor of $1.22 / 0.71 \approx 1.73$. The leverage-based method gets it exactly right.</p>

          <h3>The Leverage Dispersion Diagnostic</h3>

          <p>Define the <strong>leverage dispersion ratio</strong>:</p>

          $$\hat{\eta} = \frac{\text{std}(h)}{\text{mean}(h)}$$

          <p>computed over the calibration set. Since $\text{mean}(h_i) = p/n_1$ for training leverages (and approximately $p/n_1$ for new points), this ratio measures how spread out the leverages are relative to their average.</p>

          <ul>
            <li>$\hat{\eta} > 1$: substantial leverage variation. Some points have leverage several times the average. Leverage weighting will produce noticeably better conditional coverage than vanilla CP.</li>
            <li>$0.5 < \hat{\eta} < 1$: moderate variation. Leverage weighting improves over vanilla, but the gap may be modest.</li>
            <li>$\hat{\eta} < 0.5$: mild variation. Leverages are concentrated near their mean, and leverage-weighted intervals will be similar to constant-width intervals.</li>
          </ul>

          <h3>Beyond Homoscedastic Noise</h3>

          <p>The weight $w(h) = (1+h)^{-1/2}$ is derived under homoscedastic noise: $\text{Var}(\varepsilon \mid X) = \sigma^2$. What if the noise is itself heteroscedastic, with variance depending on leverage?</p>

          <p>If $\text{Var}(\varepsilon \mid X) = \sigma^2 g(h(X))$ for some function $g$, then the total prediction error variance becomes:</p>

          $$\text{Var}(Y_{\text{new}} - \hat{Y}(x) \mid x) \approx \sigma^2\bigl(g(h(x)) + h(x)\bigr)$$

          <p>The first term is the noise variance; the second is the estimation variance amplified by leverage. The optimal weight is:</p>

          $$w^*(h) = \bigl(g(h) + h\bigr)^{-1/2}$$

          <p>Special cases:</p>
          <ul>
            <li><strong>Homoscedastic</strong> ($g = 1$): $w^*(h) = (1 + h)^{-1/2}$. This is the standard leverage-based weight.</li>
            <li><strong>Leverage-proportional noise</strong> ($g(h) = 1 + h$): $w^*(h) = (1 + 2h)^{-1/2}$. Both noise and estimation variance grow with leverage; the weight compensates for both.</li>
          </ul>

          <p>The key observation is that $w^*$ is still a function of leverage alone. No auxiliary model is needed &mdash; just the right functional form applied to a quantity we already have.</p>

          <h3>Full Comparison</h3>

          <table>
            <thead>
              <tr>
                <th>Property</th>
                <th>Leverage</th>
                <th>CQR</th>
                <th>Studentized CP</th>
                <th>Localized CP</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Closed-form weight</td>
                <td>Yes</td>
                <td>No</td>
                <td>No</td>
                <td>N/A</td>
              </tr>
              <tr>
                <td>No auxiliary model</td>
                <td>Yes</td>
                <td>No (2 models)</td>
                <td>No (1 model)</td>
                <td>Yes</td>
              </tr>
              <tr>
                <td>No hyperparameters</td>
                <td>Yes</td>
                <td>Many</td>
                <td>Several</td>
                <td>Kernel + bandwidth</td>
              </tr>
              <tr>
                <td>Immune to sign flip</td>
                <td>Yes</td>
                <td>Partial</td>
                <td>No</td>
                <td>Yes</td>
              </tr>
              <tr>
                <td>Cost per test point</td>
                <td>$O(p)$</td>
                <td>$O(1)$ after training</td>
                <td>$O(1)$ after training</td>
                <td>$O(n_2)$</td>
              </tr>
              <tr>
                <td>Computed from design matrix</td>
                <td>Yes</td>
                <td>No</td>
                <td>No</td>
                <td>No</td>
              </tr>
              <tr>
                <td>Exact variance formula</td>
                <td>Yes</td>
                <td>Approximate</td>
                <td>Approximate</td>
                <td>Asymptotic</td>
              </tr>
            </tbody>
          </table>

        </div>
      </div>

      <!-- =========================================================== -->
      <!-- LEVEL 3: ADVANCED                                           -->
      <!-- =========================================================== -->
      <div class="level">
        <div class="level-header" onclick="this.parentElement.querySelector('.level-content').classList.toggle('collapsed'); this.setAttribute('aria-expanded', this.getAttribute('aria-expanded')==='true'?'false':'true');" aria-expanded="true">
          <span class="level-badge advanced">Advanced</span>
          <h2>Formal Justifications and Extensions</h2>
          <span class="level-toggle">&#9662;</span>
        </div>
        <div class="level-content">

          <h3>Formal Statement of the Four Properties</h3>

          <p><strong>Property 1 (Closed-Form).</strong> Let $Y = X^\top\beta + \varepsilon$ with $\varepsilon \sim (0, \sigma^2)$ and $\hat{\beta} = (\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top\mathbf{Y}$ the OLS estimator. For a new point $x$ independent of the training data:</p>

          $$\text{Var}(Y_{\text{new}} - x^\top\hat{\beta}) = \sigma^2(1 + h(x)), \quad h(x) = x^\top(\mathbf{X}^\top\mathbf{X})^{-1}x$$

          <p>This is exact (not asymptotic) under the stated assumptions. The variance-stabilizing weight $w(h) = (1+h)^{-1/2}$ follows immediately: after dividing by $\sqrt{1+h(x)}$, the normalized residuals have constant variance $\sigma^2$.</p>

          <p><em>Proof sketch.</em> Write $Y_{\text{new}} - x^\top\hat{\beta} = \varepsilon_{\text{new}} - x^\top(\hat{\beta} - \beta)$. The two terms are independent (new noise vs. estimation error). $\text{Var}(\varepsilon_{\text{new}}) = \sigma^2$. $\text{Var}(x^\top(\hat{\beta} - \beta)) = \sigma^2 x^\top(\mathbf{X}^\top\mathbf{X})^{-1}x = \sigma^2 h(x)$. Summing gives $\sigma^2(1 + h(x))$.</p>

          <p><strong>Property 2 (Model-Free).</strong> The leverage $h(x) = x^\top(\mathbf{X}^\top\mathbf{X})^{-1}x$ depends only on the design matrix $\mathbf{X}$ and the test point $x$. It is invariant to:</p>
          <ul>
            <li>The response vector $\mathbf{Y}$.</li>
            <li>The fitted model $\hat{f}$ (OLS, ridge, random forest, etc.).</li>
            <li>The noise distribution beyond its variance.</li>
          </ul>

          <p>For weighted split conformal prediction, the coverage guarantee $\mathbb{P}(Y_{n+1} \in \hat{C}(X_{n+1})) \geq 1 - \alpha$ holds for any weight function $w$ and any model $\hat{f}$, provided the calibration data and test point are exchangeable. Therefore, using leverage-based weights with a non-OLS model preserves the marginal coverage guarantee by construction.</p>

          <p><strong>Property 3 (Computational Cost).</strong> The cost accounting is as follows:</p>

          <table>
            <thead>
              <tr>
                <th>Operation</th>
                <th>Cost</th>
                <th>Already computed?</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Thin SVD of $\mathbf{X} \in \mathbb{R}^{n_1 \times p}$</td>
                <td>$O(n_1 p^2)$</td>
                <td>Yes (OLS fitting)</td>
              </tr>
              <tr>
                <td>Store $\mathbf{\Sigma}^{-1}\mathbf{V}^\top \in \mathbb{R}^{p \times p}$</td>
                <td>$O(p^2)$</td>
                <td>Trivial</td>
              </tr>
              <tr>
                <td>$h(x_i)$ for $n_2$ calibration points</td>
                <td>$O(n_2 \cdot p)$</td>
                <td>No (extra cost)</td>
              </tr>
              <tr>
                <td>$h(x)$ for $n_{\text{test}}$ test points</td>
                <td>$O(n_{\text{test}} \cdot p)$</td>
                <td>No (extra cost)</td>
              </tr>
            </tbody>
          </table>

          <p>Total <em>additional</em> cost: $O(n_1 p^2 + n_2 p + n_{\text{test}} \cdot p)$, dominated by the SVD if not already computed, or $O((n_2 + n_{\text{test}}) \cdot p)$ if it is.</p>

          <p>For comparison, CQR with gradient-boosted trees (100 trees, depth 6) costs approximately $O(n_1 \cdot 100 \cdot p \cdot 6) = O(600 \cdot n_1 \cdot p)$ <em>per quantile model</em>, for a total of $O(1200 \cdot n_1 \cdot p)$. With $n_1 = 1000$ and $p = 30$, this is $\sim 3.6 \times 10^7$ operations, versus $\sim 4.5 \times 10^4$ for leverage computation of 1500 points. The ratio is approximately $800 \times$.</p>

          <p><strong>Property 4 (Sign-Flip Immunity).</strong> For a training point $i$, the residual is $e_i = Y_i - \hat{Y}_i = (I - H)_i \cdot \varepsilon$, so $\text{Var}(e_i) = \sigma^2(1 - h_i)$. For a new test point $x$, $\text{Var}(Y_{\text{new}} - \hat{Y}(x)) = \sigma^2(1 + h(x))$. The sign of the leverage contribution <em>flips</em> between training and prediction.</p>

          <p>Any method that regresses $|e_i|$ on $h_i$ to estimate $\sigma(x)$ learns the function $\sigma\sqrt{1-h}$ instead of $\sigma\sqrt{1+h}$. At the point $h = p/n_1$ (the average leverage), the relative error is:</p>

          $$\frac{\sqrt{1+p/n_1} - \sqrt{1-p/n_1}}{\sqrt{1+p/n_1}} = 1 - \sqrt{\frac{1-p/n_1}{1+p/n_1}}$$

          <p>For $p/n_1 = 0.1$, this is $\approx 10\%$. For $p/n_1 = 0.3$, this is $\approx 35\%$. The error grows with $p/n_1$ and is worst at the highest-leverage points, where accurate uncertainty estimation matters most.</p>

          <p>Leverage-based weights use $h(x)$ directly from the design matrix, never passing through the training residuals. The formula $\sigma^2(1+h)$ is the <em>prediction-time</em> variance, not an estimate of it via training residuals.</p>

          <h3>Randomized SVD</h3>

          <p>For very large datasets where even the standard SVD is expensive, <em>randomized SVD</em> (Halko, Martinsson, and Tropp, 2011) computes an approximate thin SVD in $O(n_1 p \log p)$ time &mdash; nearly linear in the data size. The approximation error is controlled and can be made arbitrarily small by oversampling a few extra dimensions. This means that leverage computation scales to datasets with millions of rows and thousands of features.</p>

          <p>The randomized SVD produces $\tilde{\mathbf{U}}, \tilde{\mathbf{\Sigma}}, \tilde{\mathbf{V}}$ such that $\|\mathbf{X} - \tilde{\mathbf{U}}\tilde{\mathbf{\Sigma}}\tilde{\mathbf{V}}^\top\|$ is close to optimal. The approximate leverage scores $\tilde{h}(x) = \|\tilde{\mathbf{\Sigma}}^{-1}\tilde{\mathbf{V}}^\top x\|^2$ satisfy $|\tilde{h}(x) - h(x)| \leq \epsilon$ for a user-chosen tolerance $\epsilon$, provided a modest oversampling parameter (typically 5-10 extra dimensions).</p>

          <h3>General Heteroscedastic Case</h3>

          <p>Suppose $\text{Var}(\varepsilon \mid X) = \sigma^2 g(h(X))$, where $g: [0,1] \to \mathbb{R}_+$ is a known or estimable function. Then:</p>

          $$\text{Var}(Y_{\text{new}} - \hat{Y}(x) \mid x) = \sigma^2 g(h(x)) + \sigma^2 h(x) = \sigma^2\bigl(g(h(x)) + h(x)\bigr)$$

          <p>The optimal variance-stabilizing weight is:</p>

          $$w^*(h) = \bigl(g(h) + h\bigr)^{-1/2}$$

          <p>Important special cases and their optimal weights:</p>

          <table>
            <thead>
              <tr>
                <th>Model</th>
                <th>$g(h)$</th>
                <th>Total variance</th>
                <th>Optimal weight $w^*(h)$</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Homoscedastic</td>
                <td>$1$</td>
                <td>$\sigma^2(1+h)$</td>
                <td>$(1+h)^{-1/2}$</td>
              </tr>
              <tr>
                <td>Leverage-proportional</td>
                <td>$1 + h$</td>
                <td>$\sigma^2(1+2h)$</td>
                <td>$(1+2h)^{-1/2}$</td>
              </tr>
              <tr>
                <td>Quadratic leverage</td>
                <td>$1 + h^2$</td>
                <td>$\sigma^2(1+h+h^2)$</td>
                <td>$(1+h+h^2)^{-1/2}$</td>
              </tr>
              <tr>
                <td>General</td>
                <td>$g(h)$</td>
                <td>$\sigma^2(g(h)+h)$</td>
                <td>$(g(h)+h)^{-1/2}$</td>
              </tr>
            </tbody>
          </table>

          <p>In every case, the optimal weight depends only on $h$. The entire adaptation mechanism is a univariate function of leverage.</p>

          <h3>When Heteroscedasticity Is Not Captured by Leverage</h3>

          <p>If $\text{Var}(\varepsilon \mid X) = \sigma^2(X) $ depends on features in ways that are <em>not</em> a function of $h(X)$, leverage-based adaptation handles only the geometric (estimation-variance) component. The total prediction error variance is then:</p>

          $$\text{Var}(Y_{\text{new}} - \hat{Y}(x) \mid x) = \sigma^2(x) + \sigma_0^2 \cdot h(x)$$

          <p>where $\sigma_0^2$ is the average noise level and $\sigma^2(x)$ is the feature-dependent noise. The leverage component $\sigma_0^2 \cdot h(x)$ is still handled exactly by leverage weighting. For the non-leverage component $\sigma^2(x)$, one can combine leverage weighting with a lightweight scale estimator. A natural hybrid approach is to use a small random forest (say, 10 trees) to estimate $\hat{\sigma}(x)$ from training residuals, then define the weight as $w(x) = (\hat{\sigma}^2(x) \cdot (1 + h(x)))^{-1/2}$. The leverage component handles the geometry; the scale estimator handles the feature-dependent noise.</p>

          <p>Even in this hybrid approach, the leverage component provides a substantial portion of the adaptation for free. The scale estimator needs to capture only the residual heteroscedasticity not explained by leverage, which is a simpler estimation problem than capturing all heteroscedasticity from scratch.</p>

          <h3>Full Mathematical Pipeline</h3>

          <div class="mermaid">
flowchart TD
    A["Training Data (X, Y)"] --> B["Thin SVD: X = UΣVᵀ\nCost: O(n₁ · p²)"]
    B --> C["OLS coefficients\nβ̂ = VΣ⁻¹UᵀY"]
    B --> D["Store Σ⁻¹Vᵀ\nCost: O(p²)"]

    E["Calibration Data (Xᶜᵃˡ, Yᶜᵃˡ)"] --> F["Predictions: Ŷ = Xᶜᵃˡ · β̂"]
    E --> G["Leverage: hᵢ = ‖Σ⁻¹Vᵀxᵢ‖²\nCost: O(n₂ · p)"]

    F --> H["Residuals: rᵢ = |Yᵢ − Ŷᵢ|"]
    G --> I["Weights: wᵢ = (1 + hᵢ)⁻¹ᐟ²"]

    H --> J["Scores: sᵢ = rᵢ · wᵢ"]
    I --> J

    J --> K["Quantile: q̂ = Quantile₁₋α(s₁, ..., sₙ₂)"]

    L["Test point xₙₑw"] --> M["hₙₑw = ‖Σ⁻¹Vᵀxₙₑw‖²\nCost: O(p)"]
    M --> N["Width = q̂ / w(hₙₑw)\n= q̂ · √(1 + hₙₑw)"]

    C --> O["ŷₙₑw = xₙₑwᵀ · β̂"]
    N --> P["Interval:\n[ŷ − width, ŷ + width]"]
    O --> P

    style B fill:#e8f5e9,stroke:#2e7d32,color:#1c1917
    style D fill:#e8f5e9,stroke:#2e7d32,color:#1c1917
    style K fill:#e3f2fd,stroke:#1565c0,color:#1c1917
    style P fill:#e3f2fd,stroke:#1565c0,color:#1c1917
          </div>
          <p class="diagram-caption">The complete leverage-weighted conformal pipeline, from data to adaptive prediction intervals. Green nodes indicate components that are shared with (or already computed by) standard OLS.</p>

        </div>
      </div>

      <!-- =========================================================== -->
      <!-- CLOSING                                                     -->
      <!-- =========================================================== -->

      <h2>Looking Ahead</h2>

      <p>We have established that leverage scores satisfy a useful combination of properties: closed-form, model-free, computationally negligible, and immune to the sign flip. Among existing adaptation mechanisms for conformal prediction, none other has all four.</p>

      <p>In the next and final post, we bring everything together. We formalize the leverage-weighted conformal approach, establish its coverage guarantee, and see how all the ideas from this series combine into a single, practical method.</p>

    </div>

    <div class="further-reading">
      <h3>Further Reading</h3>
      <ul>
        <li>Hoaglin, D. C. &amp; Welsch, R. E. (1978). The hat matrix in regression and ANOVA. <em>The American Statistician</em>.</li>
        <li>Drineas, P., Mahoney, M. W., &amp; Muthukrishnan, S. (2012). Fast approximation of matrix coherence and statistical leverage. <em>JMLR</em>.</li>
        <li>Clarkson, K. L. &amp; Woodruff, D. P. (2013). Low rank approximation and regression in input sparsity time. <em>STOC</em>.</li>
      </ul>
    </div>

    <div class="post-nav">
      <a href="post08.html" class="prev">Adaptive Conformal Methods</a>
      <a href="post10.html" class="next">The Missing Connection</a>
    </div>

  </article>
</main>

<footer>
  <span>Shreyas Fadnavis</span>
  <span><a href="/blog/">Notes</a></span>
</footer>

<script src="../js/lightbox.js"></script>
</body>
</html>
