<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Notes &mdash; Shreyas Fadnavis</title>
  <link rel="stylesheet" href="../css/style.css">
</head>
<body>

<nav>
  <div class="nav-inner">
    <a href="/" class="site-mark">SF</a>
    <div class="nav-links">
      <a href="/">About</a>
      <a href="/blog/" class="active">Notes</a>
      <a href="/links.html">Links</a>
    </div>
  </div>
</nav>

<main class="notes-index">

  <section class="notes-hero">
    <div class="notes-hero-inner">
      <h1 class="notes-page-title">Notes</h1>
      <p class="notes-page-desc">On prediction intervals, uncertainty quantification, the geometry of regression, and multi-agent AI.</p>
      <p class="notes-page-intro">Each note has three levels of depth &mdash; <em>intuitive</em>, <em>technical</em>, and <em>advanced</em> &mdash; so you can read at whatever level matches your background.</p>
      <div class="notes-topic-nav">
        <a href="#conformal" class="notes-topic-link active" onclick="smoothScroll(event, 'conformal')">Conformal Prediction</a>
        <span class="notes-topic-sep">&middot;</span>
        <a href="#leverage" class="notes-topic-link" onclick="smoothScroll(event, 'leverage')">Leverage Scores</a>
        <span class="notes-topic-sep">&middot;</span>
        <a href="#agentic" class="notes-topic-link" onclick="smoothScroll(event, 'agentic')">Agentic AI</a>
      </div>
    </div>
  </section>

  <section class="notes-grid">
    <div class="notes-grid-inner">

      <!-- Column 1: Conformal Prediction -->
      <div class="notes-column" id="conformal">
        <div class="notes-column-header">
          <span class="notes-column-number">I</span>
          <h2 class="notes-column-title">Conformal Prediction</h2>
          <p class="notes-column-desc">Distribution-free prediction intervals with finite-sample guarantees &mdash; from the basic recipe to its fundamental limitations and existing attempts to overcome them.</p>
        </div>
        <ol class="notes-column-list">
          <li>
            <a href="post01.html" class="note-link">
              <span class="note-link-title">Your Model Is Confident. Should You Be?</span>
              <span class="note-link-summary">Why point predictions are incomplete, what prediction intervals actually are, and why constructing them correctly is harder than it looks.</span>
            </a>
          </li>
          <li>
            <a href="post02.html" class="note-link">
              <span class="note-link-title">Conformal Prediction</span>
              <span class="note-link-summary">The split conformal recipe: train, calibrate, quantile, done. A finite-sample coverage guarantee for any model, any distribution.</span>
            </a>
          </li>
          <li>
            <a href="post03.html" class="note-link">
              <span class="note-link-title">The Constant-Width Problem</span>
              <span class="note-link-summary">Marginal versus conditional coverage, the impossibility theorem, and why constant-width intervals hide dangerous unevenness.</span>
            </a>
          </li>
          <li>
            <a href="post07.html" class="note-link">
              <span class="note-link-title">Heteroscedasticity and Variance Stabilization</span>
              <span class="note-link-summary">When prediction difficulty varies, raw residuals are not comparable. Variance-stabilizing transformations and weighted nonconformity scores.</span>
            </a>
          </li>
          <li>
            <a href="post08.html" class="note-link">
              <span class="note-link-title">Adaptive Conformal Methods</span>
              <span class="note-link-summary">CQR, Studentized CP, and Localized CP &mdash; what each gets right, what each gets wrong, and the gap that remains.</span>
            </a>
          </li>
          <li>
            <a href="post11.html" class="note-link">
              <span class="note-link-title">The Origins of Conformal Prediction</span>
              <span class="note-link-summary">From Kolmogorov&rsquo;s foundations through Vovk&rsquo;s transductive framework to the modern split method &mdash; how conformal prediction came to be.</span>
            </a>
          </li>
          <li>
            <a href="post12.html" class="note-link">
              <span class="note-link-title">Beyond the Split</span>
              <span class="note-link-summary">Full conformal, cross-conformal, and jackknife+ &mdash; recovering statistical efficiency without giving up finite-sample coverage.</span>
            </a>
          </li>
          <li>
            <a href="post13.html" class="note-link">
              <span class="note-link-title">When Exchangeability Breaks</span>
              <span class="note-link-summary">Distribution shift, non-stationarity, and feedback loops. What happens to conformal guarantees when the real world violates the one assumption we need.</span>
            </a>
          </li>
        </ol>
      </div>

      <!-- Divider -->
      <div class="notes-divider">
        <div class="notes-divider-line"></div>
      </div>

      <!-- Column 2: Leverage Scores -->
      <div class="notes-column" id="leverage">
        <div class="notes-column-header">
          <span class="notes-column-number">II</span>
          <h2 class="notes-column-title">Leverage Scores</h2>
          <p class="notes-column-desc">The hat matrix, leverage scores, and a geometric perspective on prediction uncertainty &mdash; a classical tool that tells you where your model is extrapolating, for free.</p>
        </div>
        <ol class="notes-column-list">
          <li>
            <a href="post04.html" class="note-link">
              <span class="note-link-title">The Hat Matrix</span>
              <span class="note-link-summary">How the diagonal of a projection matrix tells you exactly how unusual each data point is, and why that matters for prediction.</span>
            </a>
          </li>
          <li>
            <a href="post05.html" class="note-link">
              <span class="note-link-title">Leverage and Influence</span>
              <span class="note-link-summary">Classical regression diagnostics, Cook&rsquo;s distance, and why randomized algorithms make leverage scalable to modern datasets.</span>
            </a>
          </li>
          <li>
            <a href="post06.html" class="note-link">
              <span class="note-link-title">The Sign Flip</span>
              <span class="note-link-summary">Training residuals have variance &sigma;&sup2;(1&minus;h); prediction errors have variance &sigma;&sup2;(1+h). The sign of leverage flips, and most methods get this wrong.</span>
            </a>
          </li>
          <li>
            <a href="post09.html" class="note-link">
              <span class="note-link-title">Leverage as a Free Lunch</span>
              <span class="note-link-summary">Closed-form, model-free, computationally negligible, and immune to the sign flip. Everything you need is already in the design matrix.</span>
            </a>
          </li>
          <li>
            <a href="post14.html" class="note-link">
              <span class="note-link-title">A Brief History of Leverage</span>
              <span class="note-link-summary">From regression diagnostics in the 1970s to randomized algorithms &mdash; how leverage scores went from a statistical curiosity to a computational workhorse.</span>
            </a>
          </li>
          <li>
            <a href="post15.html" class="note-link">
              <span class="note-link-title">Randomized NLA: Why Leverage Scores Are the Right Sampling Distribution</span>
              <span class="note-link-summary">Leverage score sampling gives optimal row sketches for least squares, matrix approximation, and beyond. The theory of Drineas, Kannan, and Mahoney.</span>
            </a>
          </li>
          <li>
            <a href="post16.html" class="note-link">
              <span class="note-link-title">Leverage in High Dimensions</span>
              <span class="note-link-summary">Ridge leverage, kernel leverage, and neural tangent leverage &mdash; extending the hat matrix beyond classical OLS to modern high-dimensional models.</span>
            </a>
          </li>
        </ol>
      </div>

      <!-- Divider -->
      <div class="notes-divider">
        <div class="notes-divider-line"></div>
      </div>

      <!-- Column 3: Agentic AI -->
      <div class="notes-column" id="agentic">
        <div class="notes-column-header">
          <span class="notes-column-number">III</span>
          <h2 class="notes-column-title">Agentic AI</h2>
          <p class="notes-column-desc">Multi-agent architectures, ensemble theory, and the mathematics of LLM collaboration &mdash; from Condorcet's Jury Theorem to Mixture of Agents and beyond.</p>
        </div>
        <ol class="notes-column-list">
          <li>
            <a href="post17.html" class="note-link">
              <span class="note-link-title">Why One Model Isn't Enough</span>
              <span class="note-link-summary">Ensemble theory, the bias-variance-diversity decomposition, and Condorcet's Jury Theorem &mdash; the theoretical case for multi-agent systems.</span>
            </a>
          </li>
          <li>
            <a href="post18.html" class="note-link">
              <span class="note-link-title">From Mixture of Experts to Mixture of Agents</span>
              <span class="note-link-summary">Three decades from MoE through sparse gating and Switch Transformers to Together AI's layered MoA architecture.</span>
            </a>
          </li>
          <li>
            <a href="post19.html" class="note-link">
              <span class="note-link-title">The Aggregation Problem</span>
              <span class="note-link-summary">Arrow's impossibility theorem, Condorcet cycles, LLM-as-Judge, and why synthesis sidesteps social choice impossibilities.</span>
            </a>
          </li>
          <li>
            <a href="post20.html" class="note-link">
              <span class="note-link-title">Reasoning Architectures</span>
              <span class="note-link-summary">Chain-of-Thought, ReAct, Tree of Thoughts, Graph of Thoughts, and GPTSwarm &mdash; the progression from linear to graph-structured reasoning.</span>
            </a>
          </li>
          <li>
            <a href="post21.html" class="note-link">
              <span class="note-link-title">Agentic RAG</span>
              <span class="note-link-summary">Self-RAG, Corrective RAG, Adaptive-RAG, and KARMA &mdash; turning retrieval from a one-shot lookup into an active research process.</span>
            </a>
          </li>
          <li>
            <a href="post22.html" class="note-link">
              <span class="note-link-title">Scaling Laws for Multi-Agent Systems</span>
              <span class="note-link-summary">When more agents help, when they don't, communication topologies, the efficiency frontier, and the open problems ahead.</span>
            </a>
          </li>
        </ol>
      </div>

    </div>
  </section>

</main>

<footer>
  <span>Shreyas Fadnavis</span>
  <div class="footer-nav">
    <a href="/">About</a>
    <a href="/links.html">Links</a>
  </div>
</footer>

<script>
function smoothScroll(e, id) {
  e.preventDefault();
  var section = document.getElementById(id);
  section.scrollIntoView({ behavior: 'smooth', block: 'start' });
  document.querySelectorAll('.notes-topic-link').forEach(function (l) { l.classList.remove('active'); });
  e.target.classList.add('active');
  history.pushState(null, '', '#' + id);
}

// Highlight active topic on scroll
var observer = new IntersectionObserver(function (entries) {
  entries.forEach(function (entry) {
    if (entry.isIntersecting) {
      document.querySelectorAll('.notes-topic-link').forEach(function (l) { l.classList.remove('active'); });
      var link = document.querySelector('.notes-topic-link[href="#' + entry.target.id + '"]');
      if (link) link.classList.add('active');
    }
  });
}, { threshold: 0.3 });

document.querySelectorAll('.notes-column').forEach(function (s) { observer.observe(s); });
</script>

<script src="../js/animations.js"></script>

</body>
</html>
